{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project 4 Group 2 final presentation\n",
    "=====\n",
    "Table of contents\n",
    "-----\n",
    "1. Import data and libraries\n",
    "2. Data adjustments\n",
    "3. Basic k-means \n",
    "4. Mini batch\n",
    "5. K++\n",
    "6. Clustering Function and plotting\n",
    "7. Results\n",
    "\n",
    "## Import of Data and libraries\n",
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import scanpy as sc\n",
    "from matplotlib import colors\n",
    "from datetime import datetime\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sc.read_10x_mtx('./data/filtered_gene_bc_matrices/hg19/', var_names='gene_symbols', cache=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data adjustments\n",
    "### Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.filter_genes(data, min_cells=1)\n",
    "\n",
    "filtered_data = np.array(data._X.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**was das FIltering macht**\n",
    "Conversion of data into a numpy array for easier handling.\n",
    "\n",
    "### Removal of outliers and PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers():\n",
    "    global pca_data\n",
    "    X_train = pca_data\n",
    "    clf = IsolationForest(behaviour=\"new\", contamination=.07, max_samples=0.25)\n",
    "    clf.fit(X_train)\n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    pca_data = X_train[np.where(y_pred_train == 1, True, False)]\n",
    "\n",
    "def pca(d, rmo=False):\n",
    "    global dim, pca_data, pbmcs, genes\n",
    "\n",
    "    dim = d\n",
    "    pca = PCA(n_components=dim)\n",
    "    pca_data = pca.fit_transform(filtered_data)\n",
    "    if rmo == True:\n",
    "        remove_outliers()\n",
    "    print(\"Sum of explained variances: \"\"%.2f\" % (sum(pca.explained_variance_ratio_)) + \"\\n\")\n",
    "    \n",
    "    pbmcs = pca_data.shape[0]\n",
    "    genes = pca_data.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA to reduce dimensionality of our data to d dimension.\n",
    "The variables **pbmcs** and **genes** describe the dimensionalty of our data.\n",
    "Removal of outliers by Isolation forest can be chosen as a parameter (**rmo**).\n",
    "\n",
    "## Basic k-means\n",
    "### Initial centroid generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_start_centroids(starttype):\n",
    "    global centroids_array, genes, pbmcs, genes\n",
    "    pbmcs = pca_data.shape[0]\n",
    "    genes = pca_data.shape[1]\n",
    "    centroids_array = np.empty([0, genes])\n",
    "\n",
    "    if starttype == \"randcell\":\n",
    "        centroids_numbers = np.random.randint(pbmcs, size=k)\n",
    "        i = 0 \n",
    "        while i < k:\n",
    "            random_cell = centroids_numbers[i]\n",
    "            centroids_array = np.append(centroids_array, [pca_data[random_cell, :]], axis=0)\n",
    "            i += 1\n",
    "\n",
    "    elif starttype == \"randnum\":\n",
    "        centroids_array = (np.amax(pca_data) - np.amin(pca_data)) * np.random.random_sample((k, genes)) + np.amin(\n",
    "            pca_data)\n",
    "    \n",
    "    elif starttype == \"k++\":\n",
    "        kppcentroids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating an empty array of centroids (**centroids_array**) which can be extended by three differnet methods.\n",
    "**\"randcell\"** selects k random samples from the given data.\n",
    "**\"randum\"** creates k new centroids by creating random numbers inbetween the maximum and minimum of the data values.\n",
    "**\"k++\"** performs the k++ centroid function.\n",
    "### Assignment of datapoints to closest centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist(cell_point, cluster_number):\n",
    "\n",
    "    return np.linalg.norm(pca_data[cell_point, :] - centroids_array[cluster_number - 1, :])\n",
    "\n",
    "\n",
    "def assign_centroids(data_array):\n",
    "    global nearest_centroid\n",
    "    i = 0\n",
    "    array_dim1 = data_array.shape[0]\n",
    "    nearest_centroid = np.zeros([array_dim1, 1])\n",
    "    \n",
    "    # loop over all datapoints\n",
    "    while i < array_dim1:\n",
    "        sml_distance = -1 # hab hier jetzt mal -1 gemacht mal schauen ob das problemlos geht\n",
    "\n",
    "        # loop over every centroid\n",
    "        j = 1\n",
    "        while j <= k:\n",
    "\n",
    "            if sml_distance == -1 or dist(i, j) < sml_distance:\n",
    "                sml_distance = dist(i, j)\n",
    "                nearest_centroid[i, 0] = j\n",
    "            j += 1\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**dist** function returns linear distance between a selected datapoint(i) and a selected centroid(j).\n",
    "Creation of nearest_centroid array consisting of datapoints and their associated closest centroid.\n",
    "### Empty check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empty_check():\n",
    "    i = 0\n",
    "    while i < k:\n",
    "        if list(nearest_centroid).count(i + 1) == 0:\n",
    "            print(\"Empty cluster! Correcting centroids.\")\n",
    "            random_start_centroids(\"randnum\")\n",
    "            assign_centroids(pca_data)\n",
    "            empty_check()\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuring, if **\"randnum\"** method is chosen, no empty clusters were generated.\n",
    "### Generation of new centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_centroids():\n",
    "    global centroids_array, centroids_oldarray, nearest_centroid_squeeze\n",
    "    centroids_oldarray = centroids_array # create copy of old array for threshold funcion\n",
    "    nearest_centroid_squeeze = np.squeeze(nearest_centroid.astype(int))\n",
    "    centroids_array = np.empty([0, genes])\n",
    "\n",
    "    i = 1\n",
    "    while i <= k:\n",
    "        calc_means = np.mean(pca_data[nearest_centroid_squeeze == i], axis = 0)\n",
    "        centroids_array = np.append(centroids_array, np.expand_dims(calc_means, axis = 0), axis = 0)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Centroids of last generation are saved as **centroids_oldarray** to calculate distance to the subsequent generation for the threshold function.\n",
    "Creation of second centroid generation by calculation of the mean of associated data points.\n",
    "### Threshholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def improv():\n",
    "    distances = []\n",
    "    i = 0\n",
    "    while i < k: \n",
    "        d = np.linalg.norm(centroids_array[i, :] - centroids_oldarray[i,:])\n",
    "        distances.append(d)\n",
    "        i += 1\n",
    "    c_str = np.array2string(np.array(distances), precision=2)\n",
    "    print(\"Distances of clusters as compared to last generation: \\n\" + str(c_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation of distance inbetween each cluster after n iterations\n",
    "### Runtime function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runtime_start():\n",
    "    global t1\n",
    "    t1 = datetime.now().time()\n",
    "\n",
    "\n",
    "def runtime_end():\n",
    "    t2 = datetime.now().time()\n",
    "    fmt = '%H:%M:%S.%f'\n",
    "    elapsed = str(datetime.strptime(str(t2), fmt) - datetime.strptime(str(t1), fmt))\n",
    "    return str(\"\\truntime: \" + elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Glaube kaum dass das eines comments bedarf oder**\n",
    "### Complete basic k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(start, k1, n_iterations, t):\n",
    "    global k\n",
    "    k = k1\n",
    "    i = 0\n",
    "    runtime_start()\n",
    "\n",
    "    random_start_centroids(start)\n",
    "    assign_centroids(pca_data)\n",
    "\n",
    "    if start == \"randnum\":\n",
    "        empty_check()\n",
    "\n",
    "    if t == None:\n",
    "\n",
    "        while i < n_iterations:\n",
    "            new_centroids()\n",
    "            assign_centroids(pca_data)\n",
    "            i += 1\n",
    "        improv()\n",
    "\n",
    "    else:\n",
    "        count = 0\n",
    "        d = t\n",
    "\n",
    "        while d >= t:\n",
    "            new_centroids()\n",
    "            assign_centroids(pca_data)\n",
    "            d = np.linalg.norm(centroids_oldarray-centroids_array)\n",
    "            count+=1\n",
    "        print(\"%s iterations were performed\" %count)\n",
    "        \n",
    "    print(\"\\nKMEANS:\")\n",
    "    print(\"\\ngroup 4_2 algorithm:\")\n",
    "    print(runtime_end())\n",
    "    print(\"\\twss: \" + str(wss('self')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function performing a basic k-means with **k(k1)** clusters until change of clusters is below the threshold **t**. If no threshold is chosen **n** iterations are performed.\n",
    "\n",
    "## Mini Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minibatch(k1, n_iterations, b):\n",
    "    global k, pca_data, nearest_centroid_squeeze, pca_data, bg, n_iterationsg, centroids_array, cnnew\n",
    "    k = k1\n",
    "    bg = b\n",
    "    n_iterationsg = n_iterations\n",
    "    runtime_start()\n",
    "    v = np.zeros((k, 1))\n",
    "    j = 1\n",
    "    random_start_centroids(\"randcell\")\n",
    "    cnnew = centroids_array\n",
    "    while (j <= n_iterations):\n",
    "        # Reduce data to batch\n",
    "        pca_batch = pca_data[np.random.randint(pca_data.shape[0], size=b), :]\n",
    "        # Start centroids\n",
    "        assign_centroids(pca_batch)\n",
    "        i = 0\n",
    "        while (i < b):\n",
    "            c = cnnew[int(nearest_centroid[i, 0])-1, :]\n",
    "            v[int((nearest_centroid[i, 0]-1)), 0] =  int(v[int((nearest_centroid[i, 0]-1)), 0]) + 1\n",
    "            n = 1/v[int((nearest_centroid[i, 0]-1)), 0]\n",
    "            cnnew[int(nearest_centroid[i, 0])-1, :] = c * (1-n) + pca_data[i, :] * n\n",
    "            i+=1\n",
    "        j+=1\n",
    "\n",
    "    centroids_array = cnnew\n",
    "    assign_centroids(pca_data)\n",
    "    nearest_centroid_squeeze = np.squeeze(nearest_centroid.astype(int))\n",
    "    print(\"\\nMINI-BATCH:\")\n",
    "    print(\"\\ngroup 4_2 algorithm:\")\n",
    "    print(runtime_end())\n",
    "    print(\"\\twss: \" + str(wss('self')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tristan das darfst du commenten**\n",
    "## K++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kppcentroids():\n",
    "    global centroids_array, dist_array, prob_array\n",
    "    first_centroid = np.random.randint(pbmcs, size=1)\n",
    "    i = 0\n",
    "    centroids_array = np.append(centroids_array, pca_data[first_centroid, :], axis=0)\n",
    "    dist_array = np.empty ([0,pbmcs])\n",
    "    prob_array = np.empty ([0,pbmcs])\n",
    "    j = 0\n",
    "     \n",
    "    while i < k - 1:\n",
    "        z = centroids_array.shape[0] + 1 \n",
    "        while j < pbmcs:\n",
    "            sml_distance = -1\n",
    "            l = 1 \n",
    "            while l < z:\n",
    "                if sml_distance == -1 or dist(j, l) < sml_distance:\n",
    "                    sml_distance = dist(j, l)\n",
    "                l += 1\n",
    "            dist_array = np.append(dist_array,sml_distance **2)        \n",
    "            j += 1\n",
    "        prob_array = dist_array / np.sum(dist_array)\n",
    "        s = np.random.choice(pbmcs,p = prob_array )\n",
    "        centroids_array = np.append(centroids_array, np.expand_dims(pca_data[s, :], axis=0), axis=0)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of emtpy centroids array similar to random method.\n",
    "First centroid is chosen randomly. \n",
    "For every conecutive centroid an array of the squared distances between each data point to its closest centroids is created (**dist_array**).\n",
    "According probability array is created with identical dimension (**prob_array**).\n",
    "Centroid array is appeneded by selecting a random datapoint with according probabilty until k centroids are generated.\n",
    "Afterwards clustering follows basic k-means algorythm.\n",
    "## Clustering Function and plotting\n",
    "### Sklearn k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sklearn_kmeans_function(var, k, start):\n",
    "    global y_sklearnkmeans, sklearn_kmeans, pca_data\n",
    "    runtime_start()\n",
    "    if start == \"randcell\" or start == \"randnum\": \n",
    "        if var == \"kmeans\":\n",
    "            sklearn_kmeans = KMeans(init='random', n_clusters=k).fit(pca_data)\n",
    "        if var == \"mini\":\n",
    "            sklearn_kmeans = MiniBatchKMeans(n_clusters=k, init = 'random', max_iter=n_iterationsg, batch_size=bg).fit(pca_data)\n",
    "    if start == \"k++\": \n",
    "        if var == \"kmeans\":\n",
    "            sklearn_kmeans = KMeans(n_clusters=k).fit(pca_data)\n",
    "        if var == \"mini\":\n",
    "            sklearn_kmeans = MiniBatchKMeans(n_clusters=k, max_iter=n_iterationsg, batch_size=bg).fit(pca_data)\n",
    "    y_sklearnkmeans = sklearn_kmeans.predict(pca_data)\n",
    "    print(\"\\nsklearn kmeans:\")\n",
    "    print(runtime_end())\n",
    "    print(\"\\twss: \" + str(wss('sklearn')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plots(add = \"\"):\n",
    "    global fig1, fig2\n",
    "    # 2D plots:\n",
    "    additional = \"\"\n",
    "    if add == \"mini\":\n",
    "        additional = \" (mini-batch)\"\n",
    "    # Kmeans\n",
    "    fig1 = plt.figure(1, figsize=[10, 5], dpi=200)\n",
    "    plt1, plt2 = fig1.subplots(1, 2)\n",
    "    plt1.scatter(pca_data[:, 0], pca_data[:, 1], c=nearest_centroid_squeeze, s=0.5, cmap='gist_rainbow')\n",
    "    plt1.plot(centroids_array[:, 0], centroids_array[:, 1], markersize=5, marker=\"s\", linestyle='None', c='w')\n",
    "    plt1.set_title('kmeans' + additional)\n",
    "    \n",
    "    # Sklearnkmeans\n",
    "    plt2.scatter(pca_data[:, 0], pca_data[:, 1], c=y_sklearnkmeans, s=0.5, cmap='gist_rainbow')\n",
    "    plt2.plot(sklearn_kmeans.cluster_centers_[:, 0], sklearn_kmeans.cluster_centers_[:, 1], markersize=5, marker=\"s\", linestyle='None', c='w')\n",
    "    plt2.set_title('sklearn kmeans' + additional)\n",
    "    \n",
    "    # 3D plots\n",
    "    if dim >= 3:\n",
    "        fig2 = plt.figure(2, figsize=[15,10], dpi=200)\n",
    "\n",
    "        # Kmeans\n",
    "        plt21 = fig2.add_subplot(221, projection = '3d')\n",
    "        plt21.scatter(pca_data[:, 1], pca_data[:, 2], pca_data[:, 0], s=2, c = nearest_centroid_squeeze, cmap='gist_rainbow')\n",
    "        plt21.plot(centroids_array[:, 0], centroids_array[:, 1], centroids_array[:, 2], markersize=5, marker=\"s\", linestyle='None', c='w')\n",
    "        plt21.set_title('3d kmeans' + additional)\n",
    "\n",
    "        # Sklearnkmeans\n",
    "        plt22 = fig2.add_subplot(222, projection = '3d')\n",
    "        plt22.scatter(pca_data[:, 1], pca_data[:, 2], pca_data[:, 0], s=2, c = y_sklearnkmeans, cmap='gist_rainbow')\n",
    "        plt22.plot(sklearn_kmeans.cluster_centers_[:, 0], sklearn_kmeans.cluster_centers_[:, 1], sklearn_kmeans.cluster_centers_[:, 2], markersize=5, marker=\"s\", linestyle='None', c='w')\n",
    "        plt22.set_title('3D kmeans by sklearn' + additional)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3D plots drinnen lassen ??**\n",
    "### Quality control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlightdiffs(start, k, max_iterations, threshold, batch_size):\n",
    "    global nearest_centroid_squeeze, centroids_array\n",
    "\n",
    "    # Performing KMeans clustering and saving results\n",
    "    kmeans(start, k, max_iterations, threshold)\n",
    "    centroids_array = centroids_array[centroids_array[:,0].argsort()]\n",
    "    assign_centroids(pca_data)\n",
    "    vr = np.squeeze(nearest_centroid.astype(int))\n",
    "\n",
    "    # Performing Mini-Batch KMeans clustering and saving results\n",
    "    minibatch(k, max_iterations, batch_size)\n",
    "    centroids_array = centroids_array[centroids_array[:,0].argsort()]\n",
    "    assign_centroids(pca_data)\n",
    "    vm = np.squeeze(nearest_centroid.astype(int))\n",
    "\n",
    "    # Compare results of both algorithms and find differences\n",
    "    vn = np.where(np.subtract(vr, vm) == 0)[0]\n",
    "    nearest_centroid_squeeze = np.squeeze(np.zeros(np.size(nearest_centroid)).astype(int))\n",
    "    np.put(nearest_centroid_squeeze, vn, 1)\n",
    "\n",
    "    # Plot\n",
    "    fig3 = plt.figure(3, figsize=[5, 5], dpi=200)\n",
    "    plt3 = fig3.subplots(1)\n",
    "    plt3.scatter(pca_data[:, 0], pca_data[:, 1], c=nearest_centroid_squeeze, s=0.5, cmap=colors.ListedColormap(['red', 'white']))\n",
    "    plt3.set_title('differences')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Once again dir überlassen t-boy, falls wir das überhaupt drinnen behalten wollen. ist halt hässlich ohne sonst weil es in der cluster() fnct steht** :D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "###  Final Clustering Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster(pcas = 5, rmo=True, variant = 'kmeans', start='randcell', k = 3, max_iterations = 10, threshold = 0.00001, batch_size = 2000, hd = False):\n",
    "    pca(pcas, rmo)\n",
    "    if hd == True:\n",
    "        highlightdiffs(start, k , max_iterations, threshold, batch_size)\n",
    "    else:\n",
    "        if variant == \"kmeans\":\n",
    "            kmeans(start, k, max_iterations, threshold)\n",
    "            sklearn_kmeans_function(\"kmeans\", k, start)\n",
    "            plots()\n",
    "\n",
    "        if variant == \"mini\":\n",
    "            minibatch(k, max_iterations, batch_size)\n",
    "            sklearn_kmeans_function(\"mini\", k, start)\n",
    "            plots(\"mini\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The depicted cluster funtion allows us to perform kmeans clustering while giving us the ability to select following parameters:\n",
    "1. Amount of principal components\n",
    "2. Removal of outliers (Y/N)\n",
    "3. Performance of k-means or mini batch k-means algorythm\n",
    "4. Method for creating the initial cluster Generation (random cells, random numbers, k++)\n",
    "5. Cluster-amount\n",
    "6. Maximum iterations (not utilizied if a threshold is defined)\n",
    "7. Minimum threshhold for change of cluster centers \n",
    "8. Batch size for mini batch k-means\n",
    "9. Adding a function that highlights differences in created plots (Y/N)\n",
    "\n",
    "By combining these features we are able to utilize the same function for all three subprojects.\n",
    "## Results\n",
    "### Basic k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster(variant = 'kmeans', start = \"randcell\", hd=False, k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini batch k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster(variant = 'mini', start = \"randcell\", hd=False, k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster(variant = 'kmeans', start = \"k++\", hd=False, k=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
